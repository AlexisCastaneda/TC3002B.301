{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U40Omk6E7V2w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "import math\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def get_lemmatized_tokens(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return lemmatized_words\n",
        "\n",
        "def get_ngram_frequencies(text, n):\n",
        "    words = get_lemmatized_tokens(text)\n",
        "    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
        "    return Counter(ngrams)\n",
        "\n",
        "def cosine_similarity(frequencies1, frequencies2):\n",
        "    intersection = set(frequencies1.keys()) & set(frequencies2.keys())\n",
        "\n",
        "    dot_product = sum(frequencies1[ngram] * frequencies2[ngram] for ngram in intersection)\n",
        "    magnitude1 = math.sqrt(sum(frequencies1[ngram] ** 2 for ngram in frequencies1.keys()))\n",
        "    magnitude2 = math.sqrt(sum(frequencies2[ngram] ** 2 for ngram in frequencies2.keys()))\n",
        "\n",
        "    if magnitude1 == 0 or magnitude2 == 0:\n",
        "        return 0\n",
        "\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "def calculate_similarity(file1, file2, n):\n",
        "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
        "        text1 = f1.read()\n",
        "        text2 = f2.read()\n",
        "\n",
        "        frequencies1 = get_ngram_frequencies(text1, n)\n",
        "        frequencies2 = get_ngram_frequencies(text2, n)\n",
        "\n",
        "        similarity = cosine_similarity(frequencies1, frequencies2)\n",
        "        percentage = round(similarity * 100, 2)\n",
        "\n",
        "        return percentage\n",
        "\n",
        "def compare_files(file1, file2_folder, n):\n",
        "    similarities = []\n",
        "    \n",
        "    for file in os.listdir(file2_folder):\n",
        "        if file.endswith(\".txt\"):\n",
        "            file2 = os.path.join(file2_folder, file)\n",
        "            similarity_percentage = calculate_similarity(file1, file2, n)\n",
        "            similarities.append((file2, similarity_percentage))\n",
        "    \n",
        "    return similarities\n",
        "\n",
        "file1 = '/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-02.txt'\n",
        "folder_path = '/content/drive/MyDrive/DATASET_IA/documentos-genuinos'\n",
        "ngram_size = 3  \n",
        "similarities = compare_files(file1, folder_path, ngram_size)\n",
        "\n",
        "for file, similarity in similarities:\n",
        "    print(f\"Similarity with {file}: {similarity}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "file1 = '/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-15.txt'\n",
        "folder_path = '/content/drive/MyDrive/DATASET_IA/documentos-genuinos'\n",
        "ngram_size = 3  \n",
        "similarities = compare_files(file1, folder_path, ngram_size)\n",
        "\n",
        "folder_path_gen = \"/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos\"\n",
        "file_names_gen = glob.glob(folder_path_gen + \"/*\")\n",
        "\n",
        "for fileMy in file_names_gen:\n",
        "  plagio = \"Docuemnto Genuino\"\n",
        "  print(fileMy)\n",
        "  similarities = compare_files(fileMy, folder_path, ngram_size)\n",
        "  for file, similarity in similarities:\n",
        "    if(similarity > 15):\n",
        "      plagio = \"Documento con plagio\"\n",
        "    #print(f\"Similarity with {file}: {similarity}%\")\n",
        "  print(plagio)\n",
        "  print(\"-------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1y68693mxJy",
        "outputId": "f980f705-26c3-4caf-ba88-f3f95619b475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-12.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-04.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-15.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-14.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-08.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-07.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-01.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-11.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-06.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-05.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-03.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-13.txt\n",
            "Documento con plagio\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-09.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-10.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/DATASET_IA/docmentos-sospechosos/FID-02.txt\n",
            "Docuemnto Genuino\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}